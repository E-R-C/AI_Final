from SOM import SOM
import cv2
import numpy as np


# track reward probably

def main():
    # setup

    # if have observation:
        # take action
        # state = process_state(observation)
        # action = select_action(state)

    # if have observation:
        # update QTable(prev_action, action, prev_state, state)
        # prev_action = action
        # prev_state = state

    # take step

    # render env


def select_action(state):
    # pick max reward index for state in qTable
    # if action chosen before, likely to pick something else
